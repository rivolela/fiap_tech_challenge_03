{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 3.1 -  Tabela de ingestão de dados\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import requests\n","from io import StringIO\n","import numpy as np\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# URL do CSV diretamente do GitHub (arquivo bruto)\n","file_path = \"https://raw.githubusercontent.com/rivolela/fiap_tech_challenge_03/ae57bb6cd423c7b38a3208c9b6ea112d168d1344/csv/data_source_tech_challenge_03.csv\"\n","\n","# Baixar o arquivo CSV\n","response = requests.get(file_path, verify=True)\n","\n","# Verificar se a requisição foi bem-sucedida\n","if response.status_code == 200:\n","    # Ler o CSV usando o delimitador correto\n","    df = pd.read_csv(StringIO(response.text), delimiter=',', quotechar='\"', engine='python', on_bad_lines='skip')\n","\n","    # Limpar os nomes das colunas removendo espaços em branco antes ou depois dos nomes\n","    df.columns = df.columns.str.strip()\n","\n","    # Colunas que precisam ser convertidas para float\n","    colunas_para_converter = [\n","        'valor_m2_novo', 'valor_m2_existente', 'taxa_inflacao_nacional',\n","        'taxa_juros_emprestimo_nacional', 'indice_preco_habitacao_alojamento_novo',\n","        'indice_preco_habitacao_alojamento_existente', 'taxa_desemprego_16_a_74_anos'\n","    ]\n","\n","    # Converter as colunas para float, lidando com erros\n","    for coluna in colunas_para_converter:\n","        df[coluna] = pd.to_numeric(df[coluna], errors='coerce')\n","\n","    print(df.info)        \n","else:\n","    print(f\"Erro ao baixar o arquivo: {response.status_code}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 - Limpar dados nulos"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Drop rows with null values\n","\n","# Create a mask to identify rows with null values\n","null_rows = df[df.isnull().any(axis=1)]\n","\n","df_clean = df.dropna()\n","\n","# Print the rows that were removed\n","print(\"Rows removed due to null values:\")\n","print(null_rows)\n","\n","print(df_clean.head)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.3 - Tratamento de colunas numéricas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Limpar os nomes das colunas removendo espaços em branco antes ou depois dos nomes\n","df_clean.columns = df_clean.columns.str.strip()\n","\n","# Lista das colunas que queremos converter para números\n","colunas_numericas = [\n","    'valor_m2_novo', 'valor_m2_existente', 'taxa_inflacao_nacional',\n","    'taxa_juros_emprestimo_nacional', 'indice_preco_habitacao_alojamento_novo',\n","    'indice_preco_habitacao_alojamento_existente', 'taxa_desemprego_16_a_74_anos'\n","]\n","\n","# Substituir vírgulas por pontos e converter para float\n","for coluna in colunas_numericas:\n","    # Verifica se a coluna está no DataFrame\n","    if coluna in df_clean.columns:\n","        # Verifica se a coluna é do tipo 'object' (string)\n","        if df_clean[coluna].dtype == 'object':\n","            df_clean.loc[:, coluna] = df_clean[coluna].str.replace(',', '.').astype(float)\n","        else:\n","            df_clean.loc[:, coluna] = df_clean[coluna].astype(float)  # Já pode converter diretamente\n","    else:\n","        print(f\"Coluna {coluna} não encontrada no DataFrame.\")\n","\n","# Exibir as primeiras linhas para verificar a conversão\n","print(df_clean[colunas_numericas].head())\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.4 - Removendo Outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Função para detectar e tratar outliers usando o método IQR\n","def tratar_outliers_iqr(df, colunas_numericas):\n","    for coluna in colunas_numericas:\n","        if coluna in df.columns:\n","            # Calcular os quartis\n","            Q1 = df[coluna].quantile(0.25)\n","            Q3 = df[coluna].quantile(0.75)\n","            IQR = Q3 - Q1\n","            \n","            # Definir limites inferior e superior\n","            limite_inferior = Q1 - 1.5 * IQR\n","            limite_superior = Q3 + 1.5 * IQR\n","            \n","            # Criar uma cópia da coluna original para comparação\n","            original_values = df[coluna].copy()\n","            \n","            # Imprimir limites para verificação\n","            print(f\"Coluna: {coluna}, Limite Inferior: {limite_inferior}, Limite Superior: {limite_superior}\")\n","            \n","            # Contar os outliers antes de tratar\n","            outliers_count_before = ((original_values < limite_inferior) | (original_values > limite_superior)).sum()\n","            print(f\"Número de outliers antes de tratamento: {outliers_count_before}\")\n","\n","            # Substituir outliers acima do limite superior com o limite superior usando .loc\n","            df.loc[df[coluna] > limite_superior, coluna] = limite_superior\n","            \n","            # Substituir outliers abaixo do limite inferior com o limite inferior usando .loc\n","            df.loc[df[coluna] < limite_inferior, coluna] = limite_inferior\n","            \n","            # Contar os outliers após tratar\n","            outliers_count_after = ((df[coluna] < limite_inferior) | (df[coluna] > limite_superior)).sum()\n","            print(f\"Número de outliers após tratamento: {outliers_count_after}\")\n","\n","            # Identificar quais valores foram atualizados\n","            updated_items = df[df[coluna] != original_values]\n","            \n","            print(f\"Outliers tratados na coluna {coluna}\")\n","            if not updated_items.empty:\n","                print(\"Valores atualizados:\")\n","                print(updated_items[[coluna]])  # Mostrar apenas a coluna atualizada\n","            else:\n","                print(\"Nenhum valor foi atualizado na coluna.\")\n","        else:\n","            print(f\"Coluna {coluna} não encontrada no DataFrame.\")\n","\n","    return df\n","\n","\n","\n","# Aplicar a função ao DataFrame\n","df_tratado = tratar_outliers_iqr(df_clean, colunas_numericas)\n","\n","# Exibir o resultado\n","#print(df_tratado[colunas_numericas].describe())\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.5 - Normalização e Padronização\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","# Defina as colunas que você deseja normalizar\n","colunas_a_normalizar = [\n","    'taxa_inflacao_nacional',\n","    'taxa_juros_emprestimo_nacional',\n","    'taxa_desemprego_16_a_74_anos'\n","]\n","\n","# Inicializar o escalador\n","scaler = StandardScaler()\n","\n","# Use .loc para garantir que estamos alterando o DataFrame corretamente\n","df_normalizado = df_tratado.copy()  # Melhor prática: faça uma cópia do DataFrame original\n","df_normalizado.loc[:, colunas_a_normalizar] = scaler.fit_transform(df_tratado[colunas_a_normalizar])\n","\n","# Exibir o DataFrame normalizado\n","print(df_normalizado[colunas_a_normalizar].head())\n","print(df_normalizado)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.6 - Codificação de Dados Categóricos\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# 1. Codificação do Periodo usando Label Encoding\n","label_encoder = LabelEncoder()\n","df_normalizado['Periodo_encoded'] = label_encoder.fit_transform(df_normalizado['Periodo'])\n","\n","# Verificar se a coluna 'Bairro' existe antes de aplicar One-Hot Encoding\n","if 'Bairro' in df_normalizado.columns:\n","    # 2. Codificação do Bairro usando One-Hot Encoding\n","    df_normalizado = pd.get_dummies(df_normalizado, columns=['Bairro'], prefix='Bairro')\n","else:\n","    print(\"Coluna 'Bairro' não encontrada no DataFrame\")\n","\n","# 3. Convertendo colunas booleanas resultantes para inteiros (0 e 1)\n","# Converter apenas as colunas que podem ser convertidas para inteiros\n","df_normalizado.loc[:, df_normalizado.columns.str.startswith('Bairro')] = df_normalizado.loc[:, df_normalizado.columns.str.startswith('Bairro')].astype(int)\n","\n","# Exibir o DataFrame com as colunas codificadas\n","print(df_normalizado)\n","\n","# Validação: Conferir as colunas codificadas\n","print(\"Colunas após codificação:\")\n","print(df_normalizado.columns)\n","\n","# Validação: Mostrar os primeiros registros\n","print(\"Primeiros registros do DataFrame:\")\n","print(df_normalizado.head())\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.7 - Engenharia de features\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Criar uma nova coluna 'media_valor_m2' que é a média entre 'valor_m2_novo' e 'valor_m2_existente'\n","df_normalizado['media_valor_m2'] = (df_normalizado['valor_m2_novo'] + df_normalizado['valor_m2_existente']) / 2\n","\n","# Exibir o DataFrame com a nova feature\n","print(df_normalizado)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.7.2 - Criação de variáveis lag (trimestral) para o cálculo temporal"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Criar variáveis de lag de 1 a 8 trimestres\n","for lag in range(1, 8):\n","    df_normalizado[f'media_valor_m2_lag_{lag}'] = df_normalizado['media_valor_m2'].shift(lag)\n","\n","\n","# Remover linhas com valores ausentes que foram gerados pela criação de lags\n","df_normalizado.dropna(inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["# 4 - Divisão dos Dados e Seleção das Características\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","# Divisão manual dos dados de treino e teste\n","# Definindo o tamanho do conjunto de treino para 80% dos dados, \n","# assim as últimas 4 linhas serão usadas para teste.\n","train_size = int(len(df_normalizado) * 0.8)\n","train, test = df_normalizado.iloc[:train_size], df_normalizado.iloc[train_size:]\n","print(f\"train_size: {train_size}\")\n","\n","# Definindo as variáveis dependentes e independentes para o conjunto de treino\n","X_train = train[['taxa_inflacao_nacional', \n","                  'taxa_juros_emprestimo_nacional', \n","                  'indice_preco_habitacao_alojamento_novo', \n","                  'indice_preco_habitacao_alojamento_existente', \n","                  'taxa_desemprego_16_a_74_anos'] +\n","                 [f'media_valor_m2_lag_{lag}' for lag in range(1, 8)]]\n","\n","y_train = train['media_valor_m2']\n","\n","X_test = test[['taxa_inflacao_nacional', \n","                'taxa_juros_emprestimo_nacional', \n","                'indice_preco_habitacao_alojamento_novo', \n","                'indice_preco_habitacao_alojamento_existente', \n","                'taxa_desemprego_16_a_74_anos'] +\n","               [f'media_valor_m2_lag_{lag}' for lag in range(1, 8)]]\n","\n","y_test = test['media_valor_m2']\n","\n","print(f\"Número de predições em testes: {len(X_test)}\")\n","\n","len"]},{"cell_type":"markdown","metadata":{},"source":["# 5 - Treino do modelo\n"]},{"cell_type":"markdown","metadata":{},"source":["## 5.1 - Modelo Escolhido"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","\n","# Criação do pipeline\n","pipeline = Pipeline([\n","    ('scaler', StandardScaler()),  # Normalização dos dados\n","    ('model', GradientBoostingRegressor())  # Modelo de regressão Gradient Boosting\n","])\n","\n","# Definindo os hiperparâmetros a serem ajustados\n","param_grid = {\n","    'model__learning_rate': [0.07],\n","    'model__max_depth': [15],\n","    'model__min_samples_leaf': [3],\n","    'model__min_samples_split': [10],\n","    'model__n_estimators': [250]\n","}\n","\n","# Configurando o GridSearchCV para procurar os melhores parâmetros\n","grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n","\n","# Ajustando o modelo com os dados de treino\n","grid_search.fit(X_train, y_train)\n","\n","# Fazendo previsões com os dados de teste\n","y_pred = grid_search.predict(X_test)\n","\n","# Cálculo do erro quadrático médio\n","mse = mean_squared_error(y_test, y_pred)  # Use y_test em vez de test['media_valor_m2']\n","print(f\"Mean Squared Error: {mse:.2f}\")\n","\n","# Mostrando os melhores hiperparâmetros\n","print(\"Melhores Hiperparâmetros:\", grid_search.best_params_)\n"]},{"cell_type":"markdown","metadata":{},"source":["# 6 - Plot modelo\n"]},{"cell_type":"markdown","metadata":{},"source":["# 8 - Previsão Futura\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","# Número de previsões futuras\n","n_futuros = 10\n","\n","# Previsões futuras (usando o código que você tem para previsões futuras)\n","future_predictions = []  # Lista para armazenar as previsões futuras\n","current_data = X_test.iloc[-1].values.reshape(1, -1)  # Obtendo os dados da última observação\n","\n","# Supondo que você tenha as colunas de lag definidas\n","lag_columns = [f'media_valor_m2_lag_{i}' for i in range(1, 8)]  # Ajuste conforme suas colunas de lag\n","\n","for t in range(n_futuros):\n","    future_pred = grid_search.predict(current_data)  # Fazendo a previsão\n","    future_predictions.append(future_pred[0])  # Armazenando a previsão\n","    \n","    # Atualizando current_data com o novo valor previsto\n","    current_data[0, -1] = future_pred[0]  # Supondo que a última coluna é a que estamos prevendo\n","    \n","    # Atualizando os lag para o próximo loop\n","    for i in range(len(lag_columns) - 1):\n","        current_data[0, i] = current_data[0, i + 1]  # Deslocando os valores de lag\n","    current_data[0, len(lag_columns) - 1] = future_pred[0]  # O novo valor previsto se torna o último lag\n","\n","# Visualização das previsões para toda a amostragem de testes\n","plt.figure(figsize=(12, 6))\n","\n","# Obtendo todos os valores reais e previstos\n","real_values = test['media_valor_m2'].values\n","predicted_values = y_pred\n","\n","# Plotando os valores reais e previstos\n","plt.plot(real_values, label='Valor Real', marker='o', linestyle='-', color='blue')\n","plt.plot(predicted_values, label='Previsão', marker='x', linestyle='--', color='orange')\n","\n","# Adicionando a linha da média real\n","plt.axhline(y=np.mean(real_values), color='r', linestyle='--', label='Média Real')\n","\n","# Concatenando as previsões futuras\n","predicted_values_extended = np.concatenate((predicted_values, future_predictions))\n","\n","\n","# Garantindo que os rótulos do eixo x correspondam aos dados\n","trimestres = test.index  # Obtendo todos os índices dos trimestres\n","\n","# Usando todos os trimestres como rótulos e adicionando rótulos para os futuros\n","future_labels = ['Futuro {}'.format(i) for i in range(1, n_futuros + 1)]\n","all_labels = np.concatenate((trimestres, future_labels))\n","\n","plt.xticks(ticks=np.arange(len(all_labels)), labels=all_labels, rotation=45)\n","\n","plt.xlabel('Observações no DF de teste')\n","plt.ylabel('Valor Médio do M²')\n","plt.plot(np.arange(len(real_values), len(real_values) + n_futuros), future_predictions, label='Previsões Futuras', marker='s', linestyle='--', color='green')\n","plt.legend()\n","plt.grid()\n","plt.tight_layout()  # Ajusta o layout para não cortar os rótulos\n","plt.title('Previsão de Valor Médio do M² - Testes e Previsões Futuras')\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":2}
